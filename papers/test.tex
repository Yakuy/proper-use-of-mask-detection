\documentclass{article}
% using timesnew roman
\usepackage{mathptmx}

\usepackage{geometry}
 \geometry{
 a4paper,
 left=40mm,
 right=30mm,
 top=30mm,
 bottom=30mm,
 }

\usepackage{float}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}

\tikzstyle{startstop} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=2.5cm, minimum height=1cm, text centered, draw=black, fill=blue!30, text width=2cm]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]
\tikzstyle{double-arrow} = [thick,<->,>=stealth]


%citation
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{daftar_pustaka.bib}
\graphicspath{ {./images/} }
\renewcommand*\contentsname{Daftar Isi}
\renewcommand{\figurename}{Figur}



\begin{document}
  \begin{titlepage}
    \begin{center}
      
      \null
      {
      	\LARGE \bfseries MAKALAH}\\
      [0.5cm]
      {\Large Sistem Pembantu Deteksi Penggunaan Masker dengan Benar\\Menggunakan Object Detection Faster R-CNN}\\
          
      \vspace{2cm}

      \begin{figure}[H]
        \centering
        \includegraphics[width=200px]{/logo/Lambang UGM.jpg}
      \end{figure}
          
      \vspace{3cm}
    
      {\Large 
      Disusun oleh Tim \bfseries Yakuy 2} {\Large :\\
      \vspace{0.5cm}
      Ardacandra Subiantoro (18/427572/PA/18532)\\
      Arief Pujo Arianto (18/430253/PA/18766)\\
      Chrystian (18/430257/PA/18770)\\
      }


      \vspace{2cm}

      {\normalsize \bfseries
      PROGRAM STUDI S1 ILMU KOMPUTER\\
      DEPARTEMEN ILMU KOMPUTER DAN ELEKTRONIKA\\
      FAKULTAS MATEMATIKA DAN ILMU PENGETAHUAN ALAM\\
      UNIVERSITAS GADJAH MADA\\
      YOGYAKARTA\\
      \vspace{0.2cm}
      2020
      }
            
    \end{center}
  \end{titlepage}

  \pagenumbering{gobble}

  \newpage
  \pagenumbering{arabic}
  \textbf{Abstrak.} 
  \par Pandemi COVID-19 membawa banyak dampak negatif bagi Indonesia dan seluruh dunia. Penggunaan masker merupakan salah satu cara efektif untuk mengurangi angka penyebaran COVID-19. Kami mengusulkan penggunaan model Faster R-CNN untuk mendeteksi penggunaan masker pada citra foto atau video. Model dilatih dengan dataset 853 gambar kumpulan orang yang digolongkan menjadi 3 kelas : menggunakan masker, tidak menggunakan masker, dan penggunaan masker tidak benar. Hasil proses pelatihan menghasilkan multi-task loss sebesar 22.4 dengan kecepatan klasifikasi 3.10 gambar per detik. Model sudah dapat mendeteksi penggunaan masker dengan efektif, sehingga model diharapkan dapat diimplementasikan untuk mendeteksi penggunaan masker dari rekaman CCTV dan memberi peringatan bila ada orang yang tidak memakai masker.
  \newpage
  \tableofcontents
  \newpage
  \section{Pendahuluan} 
  	\subsection{Latar Belakang}
	  	Meskipun berbagai penanganan sudah dilakukan tetapi hingga hari ini jumlah kasus COVID-19 terus meningkat. Jumlah kasus total COVID-19 di seluruh dunia sudah mencapai lebih dari 48 juta kasus, dengan lebih dari 1,2 juta kematian akibat COVID-19. Kasus COVID-19 di Indonesia sudah mencapai lebih dari 400 ribu dengan lebih dari 14 ribu kematian. Dampak negatif dari pandemi COVID-19 ini sangat terasa di Indonesia. Direktur Jenderal Pajak Kementerian Keuangan (Kemenkeu) Suryo Utomo membagi dampak pandemi COVID-19 menjadi tiga garis besar \cite{zuraya}. Dampak pertama adalah membuat konsumsi rumah tangga atau daya beli yang merupakan penopang 60 persen terhadap ekonomi jatuh cukup dalam. Hal ini dibuktikan dengan data dari BPS yang mencatatkan bahwa konsumsi rumah tangga turun dari 5,02 persen pada kuartal I 2019 ke 2,84 persen pada kuartal I tahun ini. Dampak kedua yaitu pandemi menimbulkan adanya ketidakpastian yang berkepanjangan sehingga investasi ikut melemah dan berimplikasi pada terhentinya usaha. Dampak ketiga adalah seluruh dunia mengalami pelemahan ekonomi sehingga menyebabkan harga komoditas turun dan ekspor Indonesia ke beberapa negara juga terhenti.
	  	
	  	\par Dengan melemahnya ekonomi di Indonesia ini, banyak perusahaan sudah mulai mencoba untuk membuka kembali bisnis mereka seperti semula. Berbagai upaya pengawasan pun dilakukan agar setiap orang dapat beraktivitas seperti semula dengan aman tanpa adanya ketakutan tertular COVID-19. Tetapi meskipun berbagai cara pengawasan sudah dilakukan, masih banyak orang yang tidak mematuhi aturan dan tetap beraktivitas seperti biasa. Perlunya banyak pengawasan untuk memperingatkan kembali aturan yang ada di era \textit{new normal} ini adalah salah satu cara agar semua dapat beraktivitas kembali seperti semula serta mengurangi resiko tertular COVID-19.
	  	
		\par Kepala Badan Nasional Penanggulanan Bencana (BNPB) menyampaikan meskipun penggunaan masker bertambah pada era \textit{new normal} ini tetapi tidak semua melakukannya dengan cara yang benar\cite{angga}. Mudah untuk mendeteksi suatu objek seperti masker tetapi sulit merelasikan hubungan untuk mengetahui apakah orang memakai masker dengan benar. Sehingga untuk mewujudkan era \textit{new normal} ini dengan baik dan efektif, dibutuhkan banyak sosialisasi, penyuluhan, pengawasan serta himbauan untuk melakukan prosedur era \textit{new normal} dengan tepat secara besar-besaran. Namun menggunakan tenaga manusia bukanlah jawaban yang tepat karena tidak efisien serta sangat sulit dan juga menyita banyak waktu apabila tenaga manusia ini harus mengawasi serta menghimbau setiap orang yang ada di setiap waktu.
		
		
  	\subsection{Rumusan Masalah}
  		Berdasarkan latar belakang tersebut permasalahan utama yang akan ditelusuri ialah :
  		\begin{enumerate}
  			\item Bagaimana penambangan data dapat membantu mewujudkan dan menegakkan aturan pada era \textit{new normal} untuk dapat mengurangi penyebaran COVID-19 yang ada ?
  			\item Bagaimana cara model dapat mendeteksi serta membedakan pemakaian masker yang baik dan benar ?

  		\end{enumerate}
  	\subsection{Batasan Masalah}
  		Batasan masalah yang akan kami gunakan adalah sebagai berikut :
  		\begin{itemize}
  			\item Dataset yang akan digunakan dibatasi pada Kaggle Face Mask Detection milik Larxel\cite{larxel_2020}.
  			\item Jenis gambar yang akan diklasifikasi dibatasi pada memakai masker, tidak memakai masker, dan memakai masker yang tidak benar.
  			\item Metode penambangan data yang akan kami gunakan adalah Real-time Object Detection dengan Arsitektur Faster R-CNN\cite{NIPS2015_14bfa6bb}.
  		\end{itemize}
  \section{Tujuan dan Manfaat}
  		\par Tujuan utama, kami mengusulkan menggunakan model Object Detection dengan arsitektur Faster R-CNN untuk membantu mengawasi dan menghimbau penggunaan masker yang benar di tempat umum. Object Detection dengan menggunakan Faster R-CNN ini diharapkan dapat dengan baik membedakan dan mengklasifikasi penggunaan masker dengan baik dan juga dapat secara cepat melakukan klasifikasi tersebut.
  		
  		\par Tujuan kedua, dari hasil penambangan data kami bertujuan untuk langsung menggunakan model tersebut diimplementasikan langsung dengan teknologi serta kesiapa infrastruktur yang ada. Implementasi ini diharapkan dapat membantu tenaga manusia untuk dapat secara otomatis menegakkan serta memperingatkan selalu penggunaan masker yang benar di tempat umum supaya era \textit{new normal} dapat dengan lancar terwujudkan. Manfaat yang kami harapkan adalah peningkatan kesadaran penggunaan masker yang benar dan kemudahan bagi tenaga manusia untuk mengawasi penggunaan masker.
  \section{Metode}
  	\subsection{Dataset}
  	Dataset yang akan digunakan untuk melatih model adalah dataset Kaggle Face Mask Detection milik Larxel\cite{larxel_2020}. Dataset berisi 853 gambar yang digolongkan menjadi 3 kelas : menggunakan masker, tidak menggunakan masker, dan masker tidak dipakai dengan benar. Tiap gambar disertai dengan keterangan \textit{bounding box} dalam format PASCAL VOC yang menunjukkan lokasi wajah dan masker. 
  	
  	\begin{figure}[H]
  		\centering
  		\includegraphics[width=400px]{/sample_dataset.png}
  		\caption{Sample Gambar Pada Dataset Kaggle Face Mask Detection}
  	\end{figure} 
  	
  	\subsection{Metode Prapemrosesan}
  	Prapemrosesan adalah semua transformasi yang diaplikasikan ke data mentah sebagai bentuk persiapan untuk dimasukkan ke algoritma pembelajaran mesin. Prapemrosesan citra mungkin memiliki efek positif pada kualitas ekstraksi fitur dan hasil analisis gambar \cite{krig}. Pelatihan pada algoritma pembelajaran dengan citra mentah tanpa adanya prapemrosesan akan menyebabkan kinerja klasifikasi yang buruk \cite{pal}.
	  	\subsubsection{Konversi ke RGB}
	  	RGB (\textit{Red, Green, Blue}) adalah model warna aditif dimana warna merah, hijau, dan biru ditambahkan bersama dengan berbagai cara untuk mereproduksikan sejumlah besar warna \cite{robert}. Tujuan utama model warna RGB adalah untuk mendeteksi, merepresentasikan, dan menampilkan gambar-gambar di sistem-sistem elektronik.
	  	\subsubsection{Normalisasi}
	  	Normalisasi adalah proses yang mengubah kisaran intensitas pixel dan memastikan setiap parameter \textit{input} memiliki ditribusi yang serupa. 
	  	Tujuan dari normalisasi pada gambar adalah untuk membuat gambar lebih akrab atau terlihat normal bagi indra manusia. Dalam kasus ini, normalisasi dilakukan dengan membagi semua intensitas pixel dalam frame dengan nilai maksimumnya yaitu 255.
	  	\subsubsection{Konversi ke PyTorch Tensor}
	  	PyTorch Tensor adalah matriks berdimensi banyak yang mengandung elemen-elemen dengan tipe data yang sama. PyTorch Tensor memiliki banyak kemiripan dengan numpy array; keduanya adalah array n-dimensional generik untuk digunakan untuk komputasi numerik. Perbedaan utamanya adalah PyTorch Tensor dapat dijalankan pada CPU atau GPU.
	  	\par
	  	Model yang digunakan pada makalah ini dijalankan menggunakan GPU, sehingga mengharuskan gambar masukan masuk dalam bentuk PyTorch Tensor. Gambar masukan yang masih dalam model warna RGB dikonversi menjadi PyTorch Tensor dengan fungsi torchvision.transforms.ToTensor(). 
  	\subsection{Pembelajaran Model}
  	 \subsubsection{Faster R-CNN}
  	 \par Faster R-CNN pertama kali dipublikasikan pada tahun 2015. Jaringan pendeteksi objek sebelum Faster R-CNN menggunakan algoritma proposal wilayah untuk membuat hipotesis lokasi objek. Jaringan seperti R-CNN dan Fast R-CNN menggunakan algoritma berbasis CPU seperti Algoritma \textit{Selective Search} yang membutuhkan waktu sekitar 2 detik untuk setiap gambar. Jaringan Faster R-CNN memperbaiki masalah ini dengan menggunakan convolutional network untuk menghasilkan proposal wilayah. Perubahan ini mengurangi waktu penghitungan proposal wilayah dari 2 detik menjadi 10 militdetik dan meningkatkan representasi fitur. Faster R-CNN terdiri dari \textit{detection pipeline} yang menggunakan RPN sebagai algoritma proposal wilayah dan Fast R-CNN sebagai jaringan detektor.\cite{shilpa_2020}
  	 
  	 \begin{figure}[H]
  	 	\centering
  	 	\includegraphics[width=300px]{arsitektur/RPN.jpeg}
  	 	\caption{Arsitektur RPN}
  	 \end{figure}
   
  	 \par RPN (\textit{Region Proposal Network}) dimulai dengan memasukkan gambar input ke dalam Backbone CNN. Gambar input diubah ukurannya sehingga sisi yang pendek 600px dan sisi yang panjang tidak lebih dari 1000px. Output dari Backbone CNN biasanya jauh lebih kecil dari ukuran gambar input, tergantung parameter stride dari Backbone CNN. Contoh Backbone CNN yang dapat digunakan adalah jaringan VGG atau ZF-Net dengan stride 16. Hal ini berarti pixel-pixel yang bersebelahan pada output jaringan sama dengan dua pixel yang terpisah sejauh 16 pixel pada gambar input. 
  	 
  	 \par Untuk setiap titik pada \textit{output feature map}, jaringan harus belajar apakah objek terdeteksi pada gambar input pada lokasi tersebut dan mengestimasi ukurannya. Hal ini dilakukan dengan meletakkan \textit{anchors} pada gambar input untuk setiap lokasi pada \textit{output feature map}.\textit{ Anchors }mengindikasikan objek-objek yang mungkin terdapat pada lokasi tersebut dengan beragam ukuran dan \textit{aspect ratio}. 
  	 
  	 \begin{figure}[H]
  	 	\centering
  	 	\includegraphics[width=300px]{arsitektur/contoh_anchor.jpeg}
  	 	\caption{Contoh "Anchors" pada Gambar Input dari Lokasi Titik A pada \textit{Feature Map}}
  	 \end{figure}
   
   	\par Jaringan bergerak melewati setiap pixel pada \textit{output feature map} dan memeriksa apakah \textit{anchors} yang mencakupi sebuah area pada gambar input mengandung objek atau tidak, lalu mengoptimalkan koordinat-koordinat \textit{anchors} untuk menghasilkan kotak-kotak pembatas yang disebut proposal wilayah.
   	
   	\par Konvolusi 3x3 dengan 512 unit diaplikasikan ke \textit{feature map} untuk menghasilkan 512-d \textit{feature map} untuk setiap lokasi. Lalu diikuti oleh 1x1 convolution layer dengan 18 unit untuk klasifikasi objek, dan 1x1 convolution dengan 36 unit untuk regresi kotak pembatas. 18 unit dari cabang klasifikasi akan mengeluarkan output dengan ukuran (H, W, 18) yang memberikan probabilitas apakah setiap titik dalam\textit{ backbone feature map }mengandung objek atau tidak di dalam semua 9 \textit{anchors} pada titik. 36 unit dari cabang regresi akan mengeluarkan output dengan ukuran (H, W, 36) yang memberikan 4 koefisien regresi  untuk setiap 9 \textit{anchors} untuk setiap titik dalam \textit{backbone feature map}. Koefisien regresi meningkatkan akurasi koordinat \textit{anchors} yang mengandung objek.
   	
   	\par \textit{Output feature map} terdiri dari 40x60 lokasi, dengan total \textit{anchors} sekitar 20 ribu. Ketika melatih model, semua \textit{anchors} yang melewati batas gambar dihiraukan supaya tidak berkontribusi dalam penghitungan loss. Sebuah \textit{anchor} dianggap sampel positif bila memenuhi salah satu kondisi :
   	\begin{enumerate}
   		\item \textit{Anchor} memiliki IoU (\textit{Intersection over Union}) tertinggi dengan kotak \textit{groundtruth}.
   		\item \textit{Anchor} memiliki IoU lebih besar dari 0.7 untuk setiap kotak \textit{groundtruth}.
   	\end{enumerate}
   	Sebuah \textit{anchor} dianggap sampel negatif bila IoU dengan semua kotak \textit{groundtruth} kurang dari 0.3. \textit{Anchor} yang tidak termasuk positif dan negatif akan dihiraukan saja.
   	
   	\par Setiap\textit{ mini-batch} untuk melatih RPN berasal dari sebuah gambar. 128 sampel positif dan 128 sampel negatif dipilih secara acak untuk menghasilkan batch. \textit{Training loss} dari RPN adalah \textit{multi-task loss} yang dihitung sebagai berikut : 
   
   	\begin{figure}[H]
   		\centering
   		\includegraphics[width=400px]{rumus/training_loss.png}
   	\end{figure}
   
   	$i$ adalah index dari \textit{anchor} dalam \textit{mini-batch}. \textit{Classification loss} adalah \textit{log loss} dari dua kelas (objek vs bukan objek). $p_{i}$ adalah nilai output dari cabang klasikasi untuk \textit{anchor} $i$, dan $p_{i}^{*}$ adalah label \textit{groundtruth}.
   	
   	\par \textit{Regression loss} diaktivasi hanya jika \textit{anchor} mengandung objek. $t_{i}$ adalah output prediksi dari cabang regresi dan terdiri dari 4 variabel [$t_{x}, t_{y}, t_{w}, t_{h}$]. \textit{Regression target} dihitung dengan rumus berikut :
   	
   	\begin{figure}[H]
   		\centering
   		\includegraphics[width=400px]{rumus/regression_target.png}
   	\end{figure}
   
   	$x, y, w, h$ adalah koordinat (x, y) dari titik tengah kotak pembatas dan tinggi(h) dan lebar(w) kotak. $x^{*}, y^{*}, w^{*}, h^{*}$ adalah koordinat dan dimensi kotak-kotak \textit{groundtruth}. Setiap\textit{ anchor} memiliki regresor yang berbeda, sehingga weight nya berbeda-beda. Ketika waktu pengujian, output regresi $t_{i}$ bisa diaplikasikan ke kotak\textit{ anchor}, dan parameter $x, y, w, h$ untuk kotak pembatas prediksi bisa dihitung dari rumus :
   	
   	\begin{figure}[H]
   		\centering
   		\includegraphics[width=400px]{rumus/regression_target_2.png}
   	\end{figure}
   	
   	\par Pada waktu pengujian, \textit{anchors} dari setiap gambar melewati beberapa langkah \textit{post-processing} untuk mengirimkan kotak-kotak pembatas objek.Koefisien regresi diaplikasikan ke \textit{anchor} untuk lokalisasi yang tepat. Untuk kumpulan kotak-kota yang tumpang tindih, kotak yang memiliki IoU lebih dari 0.7 dengan kotak lain akan dibuang. Hanya proposal kotak pembatas sejumlah $n$ terbaik dari RPN akan dipilih.
   	
   	\begin{figure}[H]
   		\centering
   		\includegraphics[width=400px]{arsitektur/full_architecture.jpeg}
   		\caption{Arsitektur Faster R-CNN Lengkap (RPN + Fast R-CNN)}
   	\end{figure}
   	
   	\par Arsitektur Faster R-CNN lengkap terdiri dari RPN sebagai algoritme proposal wilayah dan Fast R-CNN sebagai jaringan pendeteksi. Jaringan pendeteksi Fast R-CNN juga terdiri dari Backbone CNN, ROI pooling layer, dan fully-connected layer diikuti dengan dua cabang untuk klasifikasi dan regresi kotak pembatas. Gambar input dimasukkan ke Backbone CNN untuk mendapatkan \textit{feature map}. Salah satu keuntungan menggunakan RPN sebagai penghasil proposal adalah pembagian \textit{weights} antara backbone RPN dan backbone Fast R-CNN. Lalu, ROI pooling layer melakukan langkah-langkah di bawah :
   	\begin{enumerate}
   		\item Mengambil daerah proposal dari \textit{feature map} backbone.
   		\item Membagi wilayah menjadi sub-wilayah dengan jumlah tertentu.
   		\item Melakukan \textit{max-pooling} dari sub-wilayah untuk mendapatkan output dengan ukuran tertentu.
   	\end{enumerate}
   
   	\par Output ROI pooling layer dimasukkan ke dua fully-connected layer, lalu fitur-fitur dimasukkan ke cabang klasifikasi dan regresi. Cabang klasifikasi dan regresi berbeda dengan cabang klasifikasi dan regresi pada RPN. Disini classification layer memiliki $C$ unit untuk setiap kelas pada tugas deteksi. Fitur-fitur masuk melewati softmax layer untuk mendapatkan nilai klasifikasi, probabilitas proposal masuk ke dalam suatu kelas. Koefisien regresi digunakan untuk meningkatkan akurasi dari kotak pembatas. Setiap kelas memiliki regresor masing-masing dengan 4 parameter sesuai dengan $C$*4 unit output pada regression layer.
   	
   	\par Untuk memaksa jaringan untuk membagi \textit{weight} Backbone CNN antara RPN dan Fast R-CNN, digunakan proses latihan 4 langkah :
   	\begin{enumerate}
   		\item RPN dilatih secara independen seperti penjelasan di atas.
   		\item Jaringan pendeteksi Fast R-CNN juga dilatih secara independen.
   		\item \textit{Weight} RPN diinisialisasi dengan \textit{weight} Faster R-CNN, lalu dilatih untuk tugas proposal wilayah. \textit{Weight} pada lapisan-lapisan yang sama antara RPN dan Fast R-CNN tetap sama, hanya lapisan yang ada di RPN saja yang diubah.
   		\item Dengan menggunakan RPN baru, jaringan pendeteksi Fast R-CNN juga dilatih lagi. Hanya lapisan-lapisan yang ada di Fast R-CNN saja yang berubah \textit{weight} nya. 
   	\end{enumerate}
   	
   	\begin{figure}[H]
   		\centering
   		\includegraphics[width=400px]{arsitektur/contoh_hasil.png}
   		\caption{Hasil Faster R-CNN dengan Backbone VGG}
   	\end{figure}
   	
   	\subsubsection{Transfer Learning}
   	\par Transfer learning adalah metode pembelajaran mesin dimana sebuah model yang dikembangkan untuk sebuah tugas digunakan sebagai titik awal untuk model untuk tugas yang berbeda. Metode ini sering digunakan untuk deep learning, dimana model yang sudah terlatih digunakan sebagai titik awal tugas-tugas seperti visi komputer atau NLP. Tugas-tugas ini membutuhkan sumber daya komputasi dan waktu yang besar bila model dibangun tanpa transfer learning. Transfer learning mempercepat waktu pelatihan dan meningkatkan performa model.
   	
   	\par Untuk model makalah ini, titik awal model sudah dilatih dengan data pada ImageNet. ImageNet adalah database gambar yang mengandung 1.2 juta gambar yang diklasifikasi menjadi 1000 kelas. Model yang dilatih dengan ImageNet dapat mengklasifikasi gambar menjadi 1000 kelas. Weight dari \textit{pre-trained} model yang sudah dilatih dengan data ImageNet digunakan pada lapisan-lapisan awal dari model untuk mendeteksi masker. Pada model untuk mendeteksi masker, lapisan klasifikasi yang terdapat pada ujung model \textit{pre-trained} dimodifikasi supaya khusus mengklasifikasikan kelas memakai masker, tidak memakai masker, atau menggunakan masker secara salah.  
   	
   	\newpage
  	\subsection{Implementasi Weight dari Faster R-CNN Model}
  	\subsubsection{Perangkat Uji Coba}
	\par Hasil output pembelajaran Faster R-CNN adalah \textit{weights} yang dapat digunakan secara langsung untuk memuat kembali model dan memprediksi data baru dengan cepat. Untuk mengimplementasikan model secara langsung atau \textit{realtime} kami menggunakan perangkat keras : CPU Intel(R) i5-3470, GPU Nvidia GTX 960 2GB. Perangkat lunak dan \textit{libraries} : Python 3.7.7, mutils, OpenCV, pytorch, torchvision, numpy, pandas, dan ManyCam. 
	
	\par Dalam percobaan ini kami membuat 2 model program yang memiliki keunggulan masing-masing.
	\subsubsection{Program WebCam Pendeteksi Masker}
	\begin{figure}[H]
  		\centering
  		\includegraphics[width=200px]{arsitektur/Sequential Model.png}
  		\caption{Program WebCam Pendeteksi Masker Flowchart}
	\end{figure}
	Tugas dari program ini secara umum dapat dibagi menjadi 2 bagian : \\
	{\textbf{1. Proses Memuat \textit{Weights}}}
	\par Sebelum program dapat melakukan prediksi, model harus di inisialisasi atau dibuat terlebih dahulu dan selanjutnya model akan dimuat dengan \textit{Weights} yang ada dari hasil proses pembelajaran \textit{transfer learning} Faster R-CNN.\\
	{\textbf{2. Looping ketika input WebCam Aktif}}
	\par Setelah model sudah siap untuk melakukan prediksi, akan dijalankan selama WebCam aktif maka program akan membaca input yang berasal dari WebCam tersebut dan menyampaikan input tersebut kepada model. Model akan melakukan \textit{Forward Pass} menghasilkan prediksi, informasi dari prediksi ini (labels, scores, boxes) akan digambarkan pada layar, setelah proses ini selesai maka program akan mengulang mengambil input baru sampai program di tutup oleh pengguna.\\
	\par Keunggulan dari program ini adalah kesederhanaannya, program ini mengandung seluruh elemen dasar yang dibutuhkan untuk membuat program deteksi Faster-RCNN secara \textit{realtime}.
	% \subsubsection{WebCam with Mutlithreaded Model}
  	% \begin{figure}[H]
  	% 	\centering
  	% 	\includegraphics[width=400px]{arsitektur/Multithread Model.png}
  	% 	\caption{WebCam with Mutlithreaded Model Flowchart}
  	% \end{figure}
  	% Berdasarkan program dasar, program ini dapat dioptimalisasi performanya untuk terlihat lebih lancar dijalankan apabila update dari frame tidak bergantung atau terblokir menunggu hasil dari prediksi yang memakan cukup banyak waktu. Dengan menggunakan \textit{multithreading} prediksi dapat dilakukan secara asinkronus, membuat program terlihat lebih lancar. Dalam kasus ini kita dapat meminta \textit{thread 1} untuk melakukan input untuk prediksi dan langsung menggambarkan prediksi yang saat itu ada, sehingga \textit{thread 2} dapat di tugaskan untuk mengatur GPU membuat prediksi secepatnya. 
  	\subsubsection{Program WebCam Pendeteksi Masker dengan Post-processing}
  	\begin{figure}[H]
  		\centering
  		\includegraphics[width=200px]{arsitektur/Sequential with Postprocessing.png}
  		\caption{Program WebCam Pendeteksi Masker dengan Post-processing Flowchart}
	\end{figure}
	
	Kami mengusulkan program menggunakan post-processing \textit{non-maximum suppression} untuk memperjelas prediksi yang memiliki \textit{overlapping bounding box} dengan mengeliminasikan atau tidak memakai prediksi yang memiliki skor rendah dalam kotak yang sama. Hal ini terjadi karena perbedaan orang menggunakan masker, tidak menggunakan masker, dan penggunaan masker tidak benar memiliki beberapa fitur yang sama seperti memiliki mata, bentuk wajah hal ini menyebabkan label terdeteksi tetapi memiliki skor yang rendah dan sebaiknya tidak ditampilkan.\\

	\begin{figure}[H]
		\centering
		\includegraphics[width=250px]{../demo/Results/implementation/raw_prediction_nms0_labeled.png}
		\caption{Hasil prediksi program.}
	\end{figure}
	{\large{\textbf{Hasil Prediksi}}}
	\begin{table}[H]
		\centering
		\begin{tabular}{clc}
		\hline
		\textbf{i} & \textbf{Label}               & \textbf{Score}  \\ \hline
		1 & Without Mask        & \textbf{0.8836} \\
		2 & With Mask           & \textbf{0.8032} \\
		3 & With Mask Incorrect & 0.2569 \\
		4 & Without Mask        & 0.2145
		\end{tabular}
	\end{table}
	\newpage
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=250px]{../demo/Results/implementation/with_nms0.png}
		\caption{Hasil prediksi program dengan non-maximum suppression.}
  	\end{figure}
	{\large{\textbf{Hasil Prediksi Menggunakan Post-processing}}}
	\begin{table}[H]
		\centering
		\begin{tabular}{clc}
			\hline
			\textbf{i} & \textbf{Label}               & \textbf{Score}  \\ \hline
			1 & Without Mask        & \textbf{0.8836} \\
			2 & With Mask           & \textbf{0.8032} \\
		\end{tabular}
	\end{table}
	
  \newpage




  \section{Hasil}
  
  \subsection{Fungsi Loss}
  
  \begin{figure}[H]
  	\centering
  	\includegraphics[width=300px]{./images/grafik_loss.png}
  	\caption{Grafik penurunan fungsi loss pada proses pelatihan}
  \end{figure}
  
  \par \textit{Training loss} yang digunakan adalah \textit{multi-task loss} dengan rumus yang sudah diberikan pada bagian penjelasan Faster R-CNN. \textit{Multi-task loss} merupakan gabungan dari \textit{classification loss} (\textit{log loss} dari dua kelas objek vs bukan objek) serta \textit{regression loss} (\textit{log loss} dari titik tengah dan ukuran kotak prediksi dan \textit{groundtruth}). Terdapat penurunan loss signifikan dari epoch 0 sampai 10, lalu mulai mendatar dari epoch 11 sampai 25.
  
  \subsection{Hasil Program}
  
  \begin{figure}[H]
	\centering
	\includegraphics[width=400px]{./images/implementasi/hasil1.png}
	\caption{Hasil Video Demo dapat dilihat selengkapnya di \href{https://youtu.be/dnhFLPc0pXI}{youtu.be/dnhFLPc0pXI}}
  \end{figure}
  \par Hasil dari pembelajaran model Faster R-CNN sudah sangat baik dapat membedakan orang yang menggunakan masker dengan benar atau tidak memakai masker. Hasil model juga dapat mengeneralisasi dengan baik, berdasarkan dari hasil program model masih dapat melakukan \textit{object detection} pengguna masker yang belum pernah dilihat. 
  \subsubsection{Performa Program}

  
  
  \begin{figure}[H]
	\centering
	\includegraphics[height=50px]{benchmark/hasil1.png}
	\caption{\textit{screenshot} hasil performa dari Program WebCam.}
  \end{figure}

  \begin{figure}[H]
	\centering
	\includegraphics[height=50px]{benchmark/hasil2.png}
	\caption{\textit{screenshot} hasil performa dari Program WebCam dengan Post-processing (nms).}
  \end{figure}

  \begin{table}[H]
	\centering
	\begin{tabular}{lcc}
	\hline
	Program                                     & \multicolumn{1}{l}{Waktu Berlalu} & \multicolumn{1}{l}{Rata-rata Prediksi/s} \\ \hline
	WebCam Faster R-CNN                         & 61.96                             & 3.15                                     \\
	WebCam Faster R-CNN + Post-processing (nms) & 59.30                             & 3.10                                    
	\end{tabular}
	\end{table}

  Dengan menggunakan Nvidia GTX 960 2GB dan Intel® Core™ i5-3470 Processor, hasil \textit{benchmark} menunjukan Faster R-CNN dapat dengan cepat memprediksi input walaupun dengan GPU yang relatif lama. Ketika menggunakan Post-processing program harus melakukan komputasi fungsi tambahan membuat rata-rata turun tetapi tidak terlalu signifikan atau sekitar -1.58\% dari program awal. 

	\section{Kesiapan Infrastruktur}
	\par Untuk mengimplementasikan model ini infrastruktur atau alat yang dibutuhkan adalah sebuah CCTV, monitor, dan komputer. Pada hal ini komputer akan berguna sebagai alat untuk menghubungkan CCTV dengan monitor dan menjadi tempat untuk model melakukan prediksi kepada gambar input. Kemudian CCTV akan digunakan menjadi alat untuk mendapatkan gambar input yang kemudian akan diprediksi oleh model. CCTV yang digunakan akan dihubungkan langsung dengan komputer dan gambar input dari CCTV akan diproses frame by frame oleh model. Monitor akan menampilkan hasil prediksi yang telah diproses oleh komputer.
  	\begin{figure}[H]
  		\centering
  		\includegraphics[width=400px]{implementasi/test.jpg}
  		\caption{Visualisasi Implementasi}
  	\end{figure}
	\par Untuk jumlah perangkat sendiri tidak terbatas pada satu perangkat saja, jumlah perangkat dapat disesuaikan dan ditempatkan menyesuaikan dengan kebutuhan pada masing-masing tempat. Dalam monitor nanti gambar yang ditampilkan berdasarkan hasil prediksi setiap orang yang tertangkap dalam CCTV akan diberikan bounding box sesuai dengan kategori yang cocok dengan mereka. Warna dari box akan menunjukkan label berdasakan warna, warna dapat bebas dipilih dalam percobaan ini kami memakai warna hijau untuk orang yang tidak menggunakan masker, biru untuk orang yang menggunakan masker, dan merah untuk orang yang menggunakan masker secara tidak benar. Lalu jika dalam monitor terdapat orang-orang yang tidak menggunakan masker atau menggunakan masker dengan tidak benar maka dapat ditindak lanjuti seperti pengawas/petugas yang berjaga disekitar dapat menegur orang-orang tersebut sesuai dengan kebijakan pada masing-masing tempat.


  	\section{Kesimpulan}
	  \par Berdasarkan percobaan yang telah kami lakukan, model kami mencapai multi-task loss 22.4 dapat mengklasifikasikan gambar dengan kecepatan 3.10 gambar setiap detiknya. Hasil ini sudah cukup baik mengingat hardware yang kami gunakan termasuk dalam hardware yang sudah cukup lama, dengan menggunakan hardware yang memakai teknologi terbaru maka, kami yakin model kami akan mendapatkan hasil yang lebih baik lagi. Metode yang kami gunakan untuk masalah dalam makalah ini mencakup pengumpulan data, prapemrosesan, model Faster R-CNN, dan implementasi. Langkah-langkah prapemrosesan terdiri dari konversi warna ke RGB, normalisasi, dan konversi ke PyTorch Tensor.
	  
	  \par Hasil model ini kami harapkan dapat membantu tenaga manusia seperti pengawas/ petugas untuk dapat secara efisien menegakkan serta memperingatkan selalu penggunaan masker yang benar di tempat umum supaya era \textit{new normal} dapat dengan lancar terwujudkan. Kami juga berharap terjadinya peningkatan kesadaran penggunaan masker yang benar pada masyarakat.

	
  	
  \section{Lampiran}
  \noindent Hasil, kode program serta dokumentasi dapat ditemukan pada pranala berikut\\
  \href{https://github.com/Yakuy/Codig-3.0}{GitHub.com/Yakuy/Codig-3.0}\\

  \newpage
  \printbibliography[title={Referensi}]
\end{document}